{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CameraCalibration(images,objpoints,imgpoints):\n",
    "    \n",
    "    objp = np.zeros( (6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x, y coordinates\n",
    "    \n",
    "    for fname in images:\n",
    "        \n",
    "        img = mpimg.imread(fname)\n",
    "        \n",
    "        #Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "        \n",
    "        # If found, draw corners \n",
    "        if ret == True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9, 6), corners, ret)\n",
    "            \n",
    "def Cal_undistort(test_img, objpoints, imgpoints, mtx, dist):\n",
    "    \n",
    "    #Undistort test image using object points and image points\n",
    "    a1 = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    \n",
    "    return a1\n",
    "\n",
    "def WarpPerspective(test_img, mtx, dist):\n",
    "    \n",
    "    # Grab the image shape\n",
    "    img_size = (test_img.shape[1], test_img.shape[0]) #test_img.shape[1], [0] each mean width and height of the image. \n",
    "    width = test_img.shape[1]\n",
    "    height = test_img.shape[0]\n",
    "    \n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    src = np.float32(\n",
    "        [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "        [((img_size[0] / 6) - 10), img_size[1]],\n",
    "        [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "        [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])\n",
    "\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result \n",
    "    # again, not exact, but close enough for our purposes\n",
    "    dst = np.float32(\n",
    "        [[(width / 4), 0],\n",
    "        [(width / 4), img_size[1]],\n",
    "        [(width * 3 / 4), img_size[1]],\n",
    "        [(width * 3 / 4), 0]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(test_img, M, img_size)\n",
    "    \n",
    "    return warped, M, src, dst\n",
    "\n",
    "def luv_thresh(img, thresh=(225, 255)):\n",
    "    \n",
    "    #Convert RGB to HLS and threshold to binary image using S channel\n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "    sxbinary = np.zeros_like(l_channel)\n",
    "    sxbinary[(l_channel > thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    return sxbinary\n",
    "\n",
    "def hls_thresh(img, thresh=(180, 255)):\n",
    "    \n",
    "    #Convert RGB to HLS and threshold to binary image using S channel\n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    sxbinary = np.zeros_like(s_channel)\n",
    "    sxbinary[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return sxbinary\n",
    "\n",
    "def lab_bthresh(img, thresh=(155, 200)):\n",
    "    # 1) Convert to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    lab_b = lab[:,:,2]\n",
    "    # 2) Apply a threshold to the L channel\n",
    "    sxbinary = np.zeros_like(lab_b)\n",
    "    sxbinary[((lab_b > thresh[0]) & (lab_b <= thresh[1]))] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return sxbinary\n",
    "\n",
    "def combined_thresh(img):\n",
    "    \n",
    "    #combined with luv l and lab b of the gradient\n",
    "    hls_bin = hls_thresh(img, thresh=(180, 255))\n",
    "    luv_bin = luv_thresh(img, thresh=(225, 255))\n",
    "    lab_bin = lab_bthresh(img, thresh=(155, 200))\n",
    "    combined = np.zeros_like(hls_bin)\n",
    "    combined[(luv_bin == 1) | (lab_bin == 1) ] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        \n",
    "        # Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    \n",
    "    left_fit, right_fit, leftx, lefty, rightx, righty = find_lane_pixels(binary_warped)\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    ### Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    car_position = binary_warped.shape[1]/2 # Car's position in any frame\n",
    "    xm_per_pix = 3.7/700 # convert pixel size to real size.\n",
    "\n",
    "    car_y = binary_warped.shape[0] - 1 # Y position of the car to calculate polynomial of the car.\n",
    "    car_x_left = left_fit[0]*(car_y**2) + left_fit[1]*car_y + left_fit[2] # Finding the distance car turned left\n",
    "    car_x_right = right_fit[0]*(car_y**2) + right_fit[1]*car_y + right_fit[2] # finding the distance car turned right\n",
    "    \n",
    "    lane_center_position = (car_x_left + car_x_right)/2 # Needed to be divided by 2 to find value of turns.\n",
    "    center_dist = (car_position - lane_center_position) # To calculate the value of distance from the cneter\n",
    "    center_dist *= xm_per_pix\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty, leftx, lefty, rightx ,righty, result, center_dist\n",
    "\n",
    "\n",
    "def generate_data(output,leftx,lefty,rightx,righty,ym_per_pix, xm_per_pix):\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, output.shape[0]-1, output.shape[0])\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    return ploty, left_fit_cr, right_fit_cr\n",
    "\n",
    "def measure_curvature_real(out_img,leftx,lefty,rightx,righty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Start by generating our fake example data\n",
    "    # Make sure to feed in your real data instead in your project!\n",
    "    ploty, left_fit_cr, right_fit_cr = generate_data(out_img,leftx,lefty,rightx,righty,ym_per_pix,xm_per_pix)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "CameraCalibration(images,objpoints,imgpoints) # Function to find the corners\n",
    "\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "#Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#Calibrate camera using cv2.calibrate pre-defined library\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1] , None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    result=Cal_undistort(image, objpoints, imgpoints, mtx, dist) # Funtion to calibrate camera and undistort the images.\n",
    "    output = combined_thresh(result)\n",
    "    top_down, perspective_M, src, dst= WarpPerspective(output, mtx, dist)\n",
    "    Minv = np.linalg.inv(perspective_M)\n",
    "    \n",
    "    # Grapping left fitted x and right fitted x also to use measure_curvature_real function, \n",
    "    # extracting leftx, lefty, rightx, righty values.\n",
    "    # Finally, in serach_around_poly I grabbed offset of the car from the center\n",
    "    left_fitx, right_fitx, ploty, leftx,lefty,rightx,righty,out_img,center_dist = search_around_poly(top_down)\n",
    "    \n",
    "    # To grap the curvature of left and right\n",
    "    left,right = measure_curvature_real(top_down,leftx,lefty,rightx,righty)\n",
    "    curvature = (left+right)/2\n",
    "    \n",
    "    \"\"\"Image visualization to plot back to original image\"\"\"\n",
    "    warp_zero = np.zeros_like(top_down).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    FinalOutput = cv2.addWeighted(result, 1, newwarp, 0.3, 0)\n",
    "    \"\"\"Image visualization end\"\"\"\n",
    "    \n",
    "    if center_dist > 0:\n",
    "        direction = 'right'\n",
    "    else:\n",
    "        direction = 'left' \n",
    "    abs_center_dist = abs(center_dist)\n",
    "    text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    cv2.putText(FinalOutput, text, (100,150), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), lineType=cv2.LINE_AA)\n",
    "    cv2.putText(FinalOutput, 'Road Curvature:' +str(curvature) +' m', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), lineType=cv2.LINE_AA) \n",
    "    \n",
    "        \n",
    "    \n",
    "    return FinalOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/output_video.mp4\n",
      "[MoviePy] Writing video test_videos_output/output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [10:31<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/output_video.mp4 \n",
      "\n",
      "CPU times: user 6min 49s, sys: 1min 31s, total: 8min 20s\n",
      "Wall time: 10min 34s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "final_output = 'output_video.mp4' # the name of output file\n",
    "clip1 = VideoFileClip(\"project_video.mp4\") # You have to specify a folder of input file and input file name\n",
    "test_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time test_clip.write_videofile('test_videos_output/' + final_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mtx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be2bfe43208a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/test1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3af24c0fcd9b>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCal_undistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Funtion to calibrate camera and undistort the images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtop_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperspective_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mWarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mtx' referenced before assignment"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-4-3af24c0fcd9b>\u001b[0m(3)\u001b[0;36mprocess_image\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCal_undistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Funtion to calibrate camera and undistort the images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mtop_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperspective_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mWarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "output = process_image(image)\n",
    "#print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
